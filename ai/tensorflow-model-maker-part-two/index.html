<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Deploying Object Detection App into Android & EDGE Devices part Two | AI Vision</title><meta name=keywords content="AI,Machine Learning,Data,AutoML"><meta name=description content="In this post, we will demonstrate how to deploy the object detection model that we built in the previous post to both Android and edge devices. The model was built using the TensorFlow Model Maker API and the efficientdet-lite model, which is optimized for mobile and edge devices"><meta name=author content="Abdullah Al Hadrami"><link rel=canonical href=https://www.aivision.app/ai/tensorflow-model-maker-part-two/><link crossorigin=anonymous href=/assets/css/stylesheet.bc1149f4a72aa4858d3a9f71462f75e5884ffe8073ea9d6d5761d5663d651e20.css integrity="sha256-vBFJ9KcqpIWNOp9xRi915YhP/oBz6p1tV2HVZj1lHiA=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://www.aivision.app/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://www.aivision.app/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://www.aivision.app/favicon-32x32.png><link rel=apple-touch-icon href=https://www.aivision.app/apple-touch-icon.png><link rel=mask-icon href=https://www.aivision.app/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="Deploying Object Detection App into Android & EDGE Devices part Two "><meta property="og:description" content="In this post, we will demonstrate how to deploy the object detection model that we built in the previous post to both Android and edge devices. The model was built using the TensorFlow Model Maker API and the efficientdet-lite model, which is optimized for mobile and edge devices"><meta property="og:type" content="article"><meta property="og:url" content="https://www.aivision.app/ai/tensorflow-model-maker-part-two/"><meta property="article:section" content="ai"><meta property="article:modified_time" content="2022-12-17T15:57:34+04:00"><meta property="og:site_name" content="AI Vision"><meta name=twitter:card content="summary"><meta name=twitter:title content="Deploying Object Detection App into Android & EDGE Devices part Two "><meta name=twitter:description content="In this post, we will demonstrate how to deploy the object detection model that we built in the previous post to both Android and edge devices. The model was built using the TensorFlow Model Maker API and the efficientdet-lite model, which is optimized for mobile and edge devices"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"","item":"https://www.aivision.app/ai/"},{"@type":"ListItem","position":3,"name":"Deploying Object Detection App into Android \u0026 EDGE Devices part Two ","item":"https://www.aivision.app/ai/tensorflow-model-maker-part-two/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Deploying Object Detection App into Android \u0026 EDGE Devices part Two ","name":"Deploying Object Detection App into Android \u0026 EDGE Devices part Two ","description":"In this post, we will demonstrate how to deploy the object detection model that we built in the previous post to both Android and edge devices. The model was built using the TensorFlow Model Maker API and the efficientdet-lite model, which is optimized for mobile and edge devices","keywords":["AI","Machine Learning","Data","AutoML"],"articleBody":"You can refer to the previous post to learn how to build the object detection model using the TensorFlow Model Maker API and the efficientdet-lite model (https://www.aivision.app/ai/tensorflow-model-maker-part-two/)\nLive Demo for Android and EDGE Device Here is the live demo for Object Detection App on Android and Edge Devices.\n1 Youtube link Clone the Repo 1 2 3 git clone Building the Object Detection App for Android Prerequisites Android Studio Android Device with Android 8 or higher. Once you have cloned the repo, you can open the project in Android Studio. The project is located in the android_od folder.\nRunning the App once you open the project, Wait for the gradle to build the project and then you can run the app on your Android device, make sure the usb debugging is enabled on your device and you have connected it to your computer.\nBuilding the App with your own model if you built your own model and want to use it in the app, you can replace the model file located in android_od/app/src/main/assets with your own model file. then replace the model name in the file ObjectDetectorHelper.kt in the method setupObjectDetector() with your model name , line 85 , if you built only on model just assign the model name to the variable modelName like this:\n1 2 val modelName = \"YourModel.tflite\" if you built multiple models, you can use the when statement to assign the model name to the variable modelName like this , assuming you built 5 models\n1 2 3 4 5 6 7 8 9 val modelName = when (currentModel) { MODEL_EFFICIENTDETV0 -\u003e \"Apple_Orange_arch0.tflite\" MODEL_EFFICIENTDETV1 -\u003e \"Apple_Orange_arch1.tflite\" MODEL_EFFICIENTDETV2 -\u003e \"Apple_Orange_arch2.tflite\" MODEL_EFFICIENTDETV3 -\u003e \"Apple_Orange_arch3.tflite\" else -\u003e \"Apple_Orange_arch4.tflite\" } make sure to replace the model names with your own model names. then you can build and run the app on your Android device.\nBuilding the Object Detection App for Edge Devices Prerequisites PC or Raspberry Pi or EDGE Device with Linux OS OS : Windows WSL2 or Linux OS(Debian, Ubuntu, etc..) Python 3.7 or higher Running the App assuming you have IP camera or webcam connected to your computer, if you don’t have one, you can use the IP camera simulator app on your phone named “IP Webcam” , search for it on the play store and install it, then run the app , from the app go to menu and select “Start Server”, the app will display the IP address and port number, you can use this IP address and port number to connect to the camera from your computer.\nthen open file detect.py and replace the IP address and port number with your own IP address and port number, line 22 , 23\n1 2 3 4 IP = '192.168.0.102' # TODO change this to your camera's IP address PORT = '8080' # TODO change this to your camera's port number URL = 'h264_ulaw.sdp' ip_camera_url = 'rtsp://' + IP + ':' + PORT + '/' + URL then run the following command to install the required packages , make sure you are in the edge_od folder\n1 pip install -r requirements.txt then run the following command to run the app\n1 python detect.py The dialog box will open with live video feed from the camera , then you can point to the objects you want to detect , in our case we are detecting apples and oranges , the app will display the detected objects with the confidence score with bounding boxes around them , you can also press the q key to quit the app.\nBuilding the App with your own model if you built your own model and want to use it in the app, you can replace the model file located in edge_od with your own model file. then replace the model name in the file detect.py line 25 with your model name , because i built 5 models, i created a dictionary to store the model names and their corresponding index, in your case you can just assign the model name to the variable selected_model like this:\n`\n1 2 3 4 5 6 7 8 9 MODEL_PATHS = { 0 : 'Apple_Orange_arch0.tflite', 1 : 'Apple_Orange_arch1.tflite', 2 : 'Apple_Orange_arch2.tflite', 3 : 'Apple_Orange_arch3.tflite', 4 : 'Apple_Orange_arch4.tflite', } selected_model = MODEL_PATHS[0] # TODO change MODEL_PATHS[0] to your model name then you can run the app with your own model.\nConclusion I hope you enjoyed this post, if you have any questions or suggestions, please reach out to me on twitter @Alhadrami\n","wordCount":"747","inLanguage":"en","datePublished":"0001-01-01T00:00:00Z","dateModified":"2022-12-17T15:57:34+04:00","author":{"@type":"Person","name":"Abdullah Al Hadrami"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://www.aivision.app/ai/tensorflow-model-maker-part-two/"},"publisher":{"@type":"Organization","name":"AI Vision","logo":{"@type":"ImageObject","url":"https://www.aivision.app/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://www.aivision.app accesskey=h title="AI Vision (Alt + H)">AI Vision</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://www.aivision.app/ai/ title=AI><span>AI</span></a></li><li><a href=https://www.aivision.app/automation/ title=Automation><span>Automation</span></a></li><li><a href=https://www.aivision.app/data/ title=Data><span>Data</span></a></li><li><a href=https://www.aivision.app/general/ title=General><span>General</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://www.aivision.app>Home</a>&nbsp;»&nbsp;<a href=https://www.aivision.app/ai/></a></div><h1 class=post-title>Deploying Object Detection App into Android & EDGE Devices part Two</h1><div class=post-description>In this post, we will demonstrate how to deploy the object detection model that we built in the previous post to both Android and edge devices. The model was built using the TensorFlow Model Maker API and the efficientdet-lite model, which is optimized for mobile and edge devices</div><div class=post-meta>4 min&nbsp;·&nbsp;747 words&nbsp;·&nbsp;Abdullah Al Hadrami</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#live-demo-for-android-and-edge-device>Live Demo for Android and EDGE Device</a></li><li><a href=#clone-the-repo>Clone the Repo</a></li><li><a href=#building-the-object-detection-app-for-android>Building the Object Detection App for Android</a><ul><li><a href=#prerequisites>Prerequisites</a></li><li><a href=#running-the-app>Running the App</a></li><li><a href=#building-the-app-with-your-own-model>Building the App with your own model</a></li></ul></li><li><a href=#building-the-object-detection-app-for-edge-devices>Building the Object Detection App for Edge Devices</a><ul><li><a href=#prerequisites-1>Prerequisites</a></li><li><a href=#running-the-app-1>Running the App</a></li><li><a href=#building-the-app-with-your-own-model-1>Building the App with your own model</a></li></ul></li><li><a href=#conclusion>Conclusion</a></li></ul></nav></div></details></div><div class=post-content><p>You can refer to the previous post to learn how to build the object detection model using the TensorFlow Model Maker API and the efficientdet-lite model
(<a href=https://www.aivision.app/ai/tensorflow-model-maker-part-two/>https://www.aivision.app/ai/tensorflow-model-maker-part-two/</a>)</p><h2 id=live-demo-for-android-and-edge-device>Live Demo for Android and EDGE Device<a hidden class=anchor aria-hidden=true href=#live-demo-for-android-and-edge-device>#</a></h2><p>Here is the live demo for Object Detection App on Android and Edge Devices.</p><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">1
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>Youtube link 
</span></span></code></pre></td></tr></table></div></div><h2 id=clone-the-repo>Clone the Repo<a hidden class=anchor aria-hidden=true href=#clone-the-repo>#</a></h2><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">1
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">2
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">3
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>
</span></span><span style=display:flex><span>git clone
</span></span><span style=display:flex><span>    
</span></span></code></pre></td></tr></table></div></div><h2 id=building-the-object-detection-app-for-android>Building the Object Detection App for Android<a hidden class=anchor aria-hidden=true href=#building-the-object-detection-app-for-android>#</a></h2><h3 id=prerequisites>Prerequisites<a hidden class=anchor aria-hidden=true href=#prerequisites>#</a></h3><ul><li>Android Studio</li><li>Android Device with Android 8 or higher.</li></ul><p>Once you have cloned the repo, you can open the project in Android Studio. The project is located in the
<code>android_od</code> folder.</p><h3 id=running-the-app>Running the App<a hidden class=anchor aria-hidden=true href=#running-the-app>#</a></h3><p>once you open the project, Wait for the gradle to build the project and then you can run the app on your Android device, make sure the usb debugging is enabled on your device and you have connected it to your computer.</p><h3 id=building-the-app-with-your-own-model>Building the App with your own model<a hidden class=anchor aria-hidden=true href=#building-the-app-with-your-own-model>#</a></h3><p>if you built your own model and want to use it in the app, you can replace the model file located in
<code>android_od/app/src/main/assets</code> with your own model file.
then replace the model name in the file <code>ObjectDetectorHelper.kt</code> in the method <code>setupObjectDetector()</code> with your model name , line 85 ,
if you built only on model just assign the model name to the variable <code>modelName</code> like this:</p><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">1
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">2
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-kotlin data-lang=kotlin><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>val</span> modelName = <span style=color:#e6db74>&#34;YourModel.tflite&#34;</span>
</span></span></code></pre></td></tr></table></div></div><p>if you built multiple models, you can use the <code>when</code> statement to assign the model name to the variable <code>modelName</code> like this , assuming you built 5 models</p><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">1
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">2
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">3
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">4
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">5
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">6
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">7
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">8
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">9
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-kotlin data-lang=kotlin><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>val</span> modelName =
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>when</span> (currentModel) {
</span></span><span style=display:flex><span>                MODEL_EFFICIENTDETV0 <span style=color:#f92672>-&gt;</span> <span style=color:#e6db74>&#34;Apple_Orange_arch0.tflite&#34;</span>
</span></span><span style=display:flex><span>                MODEL_EFFICIENTDETV1 <span style=color:#f92672>-&gt;</span> <span style=color:#e6db74>&#34;Apple_Orange_arch1.tflite&#34;</span>
</span></span><span style=display:flex><span>                MODEL_EFFICIENTDETV2 <span style=color:#f92672>-&gt;</span> <span style=color:#e6db74>&#34;Apple_Orange_arch2.tflite&#34;</span>
</span></span><span style=display:flex><span>                MODEL_EFFICIENTDETV3 <span style=color:#f92672>-&gt;</span> <span style=color:#e6db74>&#34;Apple_Orange_arch3.tflite&#34;</span>
</span></span><span style=display:flex><span>                <span style=color:#66d9ef>else</span> <span style=color:#f92672>-&gt;</span> <span style=color:#e6db74>&#34;Apple_Orange_arch4.tflite&#34;</span>
</span></span><span style=display:flex><span>            }
</span></span></code></pre></td></tr></table></div></div><p>make sure to replace the model names with your own model names.
then you can build and run the app on your Android device.</p><h2 id=building-the-object-detection-app-for-edge-devices>Building the Object Detection App for Edge Devices<a hidden class=anchor aria-hidden=true href=#building-the-object-detection-app-for-edge-devices>#</a></h2><h3 id=prerequisites-1>Prerequisites<a hidden class=anchor aria-hidden=true href=#prerequisites-1>#</a></h3><ul><li>PC or Raspberry Pi or EDGE Device with Linux OS</li><li>OS : Windows WSL2 or Linux OS(Debian, Ubuntu, etc..)</li><li>Python 3.7 or higher</li></ul><h3 id=running-the-app-1>Running the App<a hidden class=anchor aria-hidden=true href=#running-the-app-1>#</a></h3><p>assuming you have IP camera or webcam connected to your computer, if you don&rsquo;t have one, you can use the IP camera simulator app on your phone named &ldquo;IP Webcam&rdquo; , search for it on the play store and install it, then run the app , from the app go to menu and select &ldquo;Start Server&rdquo;, the app will display the IP address and port number, you can use this IP address and port number to connect to the camera from your computer.</p><p>then open file <code>detect.py</code> and replace the IP address and port number with your own IP address and port number, line 22 , 23</p><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">1
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">2
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">3
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">4
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>IP <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;192.168.0.102&#39;</span> <span style=color:#75715e># TODO change this to your camera&#39;s IP address</span>
</span></span><span style=display:flex><span>PORT <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;8080&#39;</span> <span style=color:#75715e># TODO change this to your camera&#39;s port number</span>
</span></span><span style=display:flex><span>URL <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;h264_ulaw.sdp&#39;</span>
</span></span><span style=display:flex><span>ip_camera_url <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;rtsp://&#39;</span> <span style=color:#f92672>+</span> IP <span style=color:#f92672>+</span> <span style=color:#e6db74>&#39;:&#39;</span> <span style=color:#f92672>+</span> PORT <span style=color:#f92672>+</span> <span style=color:#e6db74>&#39;/&#39;</span> <span style=color:#f92672>+</span> URL
</span></span></code></pre></td></tr></table></div></div><p>then run the following command to install the required packages , make sure you are in the <code>edge_od</code> folder</p><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">1
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>    pip install -r requirements.txt
</span></span></code></pre></td></tr></table></div></div><p>then run the following command to run the app</p><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">1
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>    python detect.py
</span></span></code></pre></td></tr></table></div></div><p>The dialog box will open with live video feed from the camera , then you can point to the objects you want to detect , in our case we are detecting apples and oranges , the app will display the detected objects with the confidence score with bounding boxes around them , you can also press the <code>q</code> key to quit the app.</p><h3 id=building-the-app-with-your-own-model-1>Building the App with your own model<a hidden class=anchor aria-hidden=true href=#building-the-app-with-your-own-model-1>#</a></h3><p>if you built your own model and want to use it in the app, you can replace the model file located in
<code>edge_od</code> with your own model file.
then replace the model name in the file <code>detect.py</code> line 25 with your model name , because i built 5 models, i created a dictionary to store the model names and their corresponding index, in your case you can just assign the model name to the variable <code>selected_model</code> like this:</p><p>`</p><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">1
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">2
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">3
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">4
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">5
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">6
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">7
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">8
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">9
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>MODEL_PATHS <span style=color:#f92672>=</span> {
</span></span><span style=display:flex><span>  <span style=color:#ae81ff>0</span> : <span style=color:#e6db74>&#39;Apple_Orange_arch0.tflite&#39;</span>,
</span></span><span style=display:flex><span>  <span style=color:#ae81ff>1</span> : <span style=color:#e6db74>&#39;Apple_Orange_arch1.tflite&#39;</span>,
</span></span><span style=display:flex><span>  <span style=color:#ae81ff>2</span> : <span style=color:#e6db74>&#39;Apple_Orange_arch2.tflite&#39;</span>,
</span></span><span style=display:flex><span>  <span style=color:#ae81ff>3</span> : <span style=color:#e6db74>&#39;Apple_Orange_arch3.tflite&#39;</span>,
</span></span><span style=display:flex><span>  <span style=color:#ae81ff>4</span> : <span style=color:#e6db74>&#39;Apple_Orange_arch4.tflite&#39;</span>,
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>selected_model <span style=color:#f92672>=</span> MODEL_PATHS[<span style=color:#ae81ff>0</span>] <span style=color:#75715e># TODO change MODEL_PATHS[0] to your model name</span>
</span></span></code></pre></td></tr></table></div></div><p>then you can run the app with your own model.</p><h2 id=conclusion>Conclusion<a hidden class=anchor aria-hidden=true href=#conclusion>#</a></h2><p>I hope you enjoyed this post, if you have any questions or suggestions, please reach out to me on twitter @Alhadrami</p></div><footer class=post-footer><ul class=post-tags></ul><nav class=paginav><a class=prev href=https://www.aivision.app/ai/tensorflow-model-maker-part-one/><span class=title>« Prev</span><br><span>Building Live Detection ML Model Using Tensorflow Model Maker Part One</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2022 <a href=https://www.aivision.app>AI Vision</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>